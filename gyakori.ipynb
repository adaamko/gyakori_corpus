{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import re\n",
    "import numpy as np\n",
    "import json\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "corp = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"gyakori_szamitastechnika_line\", \"r+\") as f:\n",
    "    for i,line in enumerate(f):\n",
    "        obj = json.loads(line.strip(\"\\n\"))\n",
    "        corp.append(obj)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame(corp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"kategoriak\"] = df.kategoriak.apply(lambda x: x[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.kategoriak"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "p = df.groupby(\"kategoriak\").size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "p.plot.pie(figsize=(5, 5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.hosszu_kerdes.str.len()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split as split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "type(df.hosszu_kerdes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import hu_core_ud_lg\n",
    "import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm\n",
    "from gensim.models.keyedvectors import KeyedVectors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hu_nlp = hu_core_ud_lg.load()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_text(data):\n",
    "    print(len(data))\n",
    "    clean_data = []\n",
    "    for i,kerdes in tqdm(enumerate(data), \"Preprocessing\"):\n",
    "        doc = hu_nlp(data[i])\n",
    "        clean_data.append([tok.lemma_ for tok in doc if tok.is_alpha and not tok.is_stop])\n",
    "    return clean_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def vectorize(tr_data, tst_data):\n",
    "    print('\\nLoading existing FastText model...')\n",
    "    model = KeyedVectors.load_word2vec_format(\"./embeddings/hu.szte.w2v.fasttext.vec.2\")\n",
    "    vectorizer = model.wv\n",
    "    vocab_length = len(model.wv.vocab)\n",
    "    \"\"\"\n",
    "    tr_vectors = [\n",
    "        np.array([vectorizer[word] for word in tweet if word in model]).flatten() for tweet in tqdm(tr_data,'Vectorizing')\n",
    "        ]\n",
    "    max_len = np.max([len(vector) for vector in tr_vectors])\n",
    "    tr_vectors = [\n",
    "        np.array(vector.tolist()+[0 for _ in range(max_len-len(vector))]) for vector in tqdm(tr_vectors,'Finalizing')\n",
    "        ]\n",
    "    \n",
    "    tst_vectors = [\n",
    "        np.array([vectorizer[word] for word in tweet if word in model]).flatten() for tweet in tqdm(tst_data,'Vectorizing')\n",
    "        ]\n",
    "\n",
    "    tst_vectors = [\n",
    "        np.array(vector.tolist()+[0 for _ in range(max_len-len(vector))]) for vector in tqdm(tst_vectors,'Finalizing')\n",
    "        ]\n",
    "    \"\"\"\n",
    "    \n",
    "    tr_vectors = [\n",
    "        np.array(np.mean([vectorizer[word] for word in tweet if word in model], axis=0)) for tweet in tqdm(tr_data,'Vectorizing')\n",
    "    ]\n",
    "    \n",
    "    tst_vectors = [\n",
    "        np.array(np.mean([vectorizer[word] for word in tweet if word in model], axis=0)) for tweet in tqdm(tst_data,'Vectorizing')\n",
    "    ]\n",
    "    \n",
    "    return tr_vectors, tst_vectors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_features_and_labels(data, labels):\n",
    "    tr_data,tst_data,tr_labels,tst_labels = split(data,labels,test_size=0.3)\n",
    "    tr_data_clean = preprocess_text(tr_data)\n",
    "    tst_data_clean = preprocess_text(tst_data)\n",
    "    \n",
    "    tst_vecs = []\n",
    "    tr_vecs = []\n",
    "    tr_vecs, tst_vecs = vectorize(tr_data_clean, tst_data_clean)    \n",
    "    return tr_vecs, tr_labels, tst_vecs, tst_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tr_vecs, tr_labels, tst_vecs, tst_labels = get_features_and_labels(df.hosszu_kerdes.tolist(), df.kategoriak.tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.svm import LinearSVC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = LinearSVC()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.fit(tr_vecs, tr_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "y_pred = model.predict(tst_vecs)\n",
    "\n",
    "print(\"Test accuracy : {}\".format(accuracy_score(tst_labels, y_pred)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "\n",
    "print(classification_report(tst_labels, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.groupby(\"kategoriak\").size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in tst_vecs:\n",
    "    print(len(i))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"gyakori_egeszseg_10000\", \"r+\") as f:\n",
    "    data = f.read()\n",
    "    eg_corp = json.loads(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "metadata": {},
   "outputs": [],
   "source": [
    "eg = pd.DataFrame.from_dict(eg_corp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>kategoriak</th>\n",
       "      <th>valasz</th>\n",
       "      <th>hosszu_kerdes</th>\n",
       "      <th>rovid_kerdes</th>\n",
       "      <th>keywords</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>[Egészség, Sérülések, balesetek]</td>\n",
       "      <td>Komolyan az eszem megáll! Azt, hogy leforrázta...</td>\n",
       "      <td>Ma sajnos leforráztam a kisbabám lábát! Úgy go...</td>\n",
       "      <td>Ma sajnos leforráztam a kisbabám lábát! Úgy go...</td>\n",
       "      <td>[baba, forró víz, leforrázás]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>[Egészség, Mentális egészség]</td>\n",
       "      <td>Nekem sokat segített a pszichológus ebben a té...</td>\n",
       "      <td>Mi a neve ennek a mentális betegségnek? A pszi...</td>\n",
       "      <td>Mi a neve ennek a mentális betegségnek? A pszi...</td>\n",
       "      <td>[pszichológia, pszichológus, lélek, elme, fóbi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>[Egészség, Férfiak egészsége]</td>\n",
       "      <td>Miért lenne baj, hogy \"még van fitymád\"? A fér...</td>\n",
       "      <td>Az a baj ha 15 évesen még van fitymám és hogy ...</td>\n",
       "      <td>Az a baj ha 15 évesen még van fitymám és hogy ...</td>\n",
       "      <td>[fityma, egészség, pénisz, betegség, normális,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>[Egészség, Betegségek]</td>\n",
       "      <td>Legyél 1 srác és minden megjavul.</td>\n",
       "      <td>26 srác vagyok minden reggel hányinger és néha...</td>\n",
       "      <td>26 srác vagyok minden reggel hányinger és néha...</td>\n",
       "      <td>[pánikbetegség, hányinger, hasmenés]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>[Egészség, Fogak, szájápolás]</td>\n",
       "      <td>Jaja, véletlen se az orvosra hallgass, aki 6+ ...</td>\n",
       "      <td>Húzassam ki? Vagy gyökérkezelés? A bal legháts...</td>\n",
       "      <td>Húzassam ki? Vagy gyökérkezelés?</td>\n",
       "      <td>[fog, gyökérkezelés]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                         kategoriak  \\\n",
       "0  [Egészség, Sérülések, balesetek]   \n",
       "1     [Egészség, Mentális egészség]   \n",
       "2     [Egészség, Férfiak egészsége]   \n",
       "3            [Egészség, Betegségek]   \n",
       "4     [Egészség, Fogak, szájápolás]   \n",
       "\n",
       "                                              valasz  \\\n",
       "0  Komolyan az eszem megáll! Azt, hogy leforrázta...   \n",
       "1  Nekem sokat segített a pszichológus ebben a té...   \n",
       "2  Miért lenne baj, hogy \"még van fitymád\"? A fér...   \n",
       "3                  Legyél 1 srác és minden megjavul.   \n",
       "4  Jaja, véletlen se az orvosra hallgass, aki 6+ ...   \n",
       "\n",
       "                                       hosszu_kerdes  \\\n",
       "0  Ma sajnos leforráztam a kisbabám lábát! Úgy go...   \n",
       "1  Mi a neve ennek a mentális betegségnek? A pszi...   \n",
       "2  Az a baj ha 15 évesen még van fitymám és hogy ...   \n",
       "3  26 srác vagyok minden reggel hányinger és néha...   \n",
       "4  Húzassam ki? Vagy gyökérkezelés? A bal legháts...   \n",
       "\n",
       "                                        rovid_kerdes  \\\n",
       "0  Ma sajnos leforráztam a kisbabám lábát! Úgy go...   \n",
       "1  Mi a neve ennek a mentális betegségnek? A pszi...   \n",
       "2  Az a baj ha 15 évesen még van fitymám és hogy ...   \n",
       "3  26 srác vagyok minden reggel hányinger és néha...   \n",
       "4                   Húzassam ki? Vagy gyökérkezelés?   \n",
       "\n",
       "                                            keywords  \n",
       "0                      [baba, forró víz, leforrázás]  \n",
       "1  [pszichológia, pszichológus, lélek, elme, fóbi...  \n",
       "2  [fityma, egészség, pénisz, betegség, normális,...  \n",
       "3               [pánikbetegség, hányinger, hasmenés]  \n",
       "4                               [fog, gyökérkezelés]  "
      ]
     },
     "execution_count": 180,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "eg.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>kategoriak</th>\n",
       "      <th>valasz</th>\n",
       "      <th>hosszu_kerdes</th>\n",
       "      <th>rovid_kerdes</th>\n",
       "      <th>keywords</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>[Egészség, Sérülések, balesetek]</td>\n",
       "      <td>Komolyan az eszem megáll! Azt, hogy leforrázta...</td>\n",
       "      <td>Ma sajnos leforráztam a kisbabám lábát! Úgy go...</td>\n",
       "      <td>Ma sajnos leforráztam a kisbabám lábát! Úgy go...</td>\n",
       "      <td>[baba, forró víz, leforrázás]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>[Egészség, Mentális egészség]</td>\n",
       "      <td>Nekem sokat segített a pszichológus ebben a té...</td>\n",
       "      <td>Mi a neve ennek a mentális betegségnek? A pszi...</td>\n",
       "      <td>Mi a neve ennek a mentális betegségnek? A pszi...</td>\n",
       "      <td>[pszichológia, pszichológus, lélek, elme, fóbi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>[Egészség, Férfiak egészsége]</td>\n",
       "      <td>Miért lenne baj, hogy \"még van fitymád\"? A fér...</td>\n",
       "      <td>Az a baj ha 15 évesen még van fitymám és hogy ...</td>\n",
       "      <td>Az a baj ha 15 évesen még van fitymám és hogy ...</td>\n",
       "      <td>[fityma, egészség, pénisz, betegség, normális,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>[Egészség, Betegségek]</td>\n",
       "      <td>Legyél 1 srác és minden megjavul.</td>\n",
       "      <td>26 srác vagyok minden reggel hányinger és néha...</td>\n",
       "      <td>26 srác vagyok minden reggel hányinger és néha...</td>\n",
       "      <td>[pánikbetegség, hányinger, hasmenés]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>[Egészség, Fogak, szájápolás]</td>\n",
       "      <td>Jaja, véletlen se az orvosra hallgass, aki 6+ ...</td>\n",
       "      <td>Húzassam ki? Vagy gyökérkezelés? A bal legháts...</td>\n",
       "      <td>Húzassam ki? Vagy gyökérkezelés?</td>\n",
       "      <td>[fog, gyökérkezelés]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                         kategoriak  \\\n",
       "0  [Egészség, Sérülések, balesetek]   \n",
       "1     [Egészség, Mentális egészség]   \n",
       "2     [Egészség, Férfiak egészsége]   \n",
       "3            [Egészség, Betegségek]   \n",
       "4     [Egészség, Fogak, szájápolás]   \n",
       "\n",
       "                                              valasz  \\\n",
       "0  Komolyan az eszem megáll! Azt, hogy leforrázta...   \n",
       "1  Nekem sokat segített a pszichológus ebben a té...   \n",
       "2  Miért lenne baj, hogy \"még van fitymád\"? A fér...   \n",
       "3                  Legyél 1 srác és minden megjavul.   \n",
       "4  Jaja, véletlen se az orvosra hallgass, aki 6+ ...   \n",
       "\n",
       "                                       hosszu_kerdes  \\\n",
       "0  Ma sajnos leforráztam a kisbabám lábát! Úgy go...   \n",
       "1  Mi a neve ennek a mentális betegségnek? A pszi...   \n",
       "2  Az a baj ha 15 évesen még van fitymám és hogy ...   \n",
       "3  26 srác vagyok minden reggel hányinger és néha...   \n",
       "4  Húzassam ki? Vagy gyökérkezelés? A bal legháts...   \n",
       "\n",
       "                                        rovid_kerdes  \\\n",
       "0  Ma sajnos leforráztam a kisbabám lábát! Úgy go...   \n",
       "1  Mi a neve ennek a mentális betegségnek? A pszi...   \n",
       "2  Az a baj ha 15 évesen még van fitymám és hogy ...   \n",
       "3  26 srác vagyok minden reggel hányinger és néha...   \n",
       "4                   Húzassam ki? Vagy gyökérkezelés?   \n",
       "\n",
       "                                            keywords  \n",
       "0                      [baba, forró víz, leforrázás]  \n",
       "1  [pszichológia, pszichológus, lélek, elme, fóbi...  \n",
       "2  [fityma, egészség, pénisz, betegség, normális,...  \n",
       "3               [pánikbetegség, hányinger, hasmenés]  \n",
       "4                               [fog, gyökérkezelés]  "
      ]
     },
     "execution_count": 181,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "eg.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "metadata": {},
   "outputs": [],
   "source": [
    "eg[\"kategoriak\"] = eg.kategoriak.apply(lambda x: x[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>kategoriak</th>\n",
       "      <th>valasz</th>\n",
       "      <th>hosszu_kerdes</th>\n",
       "      <th>rovid_kerdes</th>\n",
       "      <th>keywords</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>Sérülések, balesetek</td>\n",
       "      <td>Komolyan az eszem megáll! Azt, hogy leforrázta...</td>\n",
       "      <td>Ma sajnos leforráztam a kisbabám lábát! Úgy go...</td>\n",
       "      <td>Ma sajnos leforráztam a kisbabám lábát! Úgy go...</td>\n",
       "      <td>[baba, forró víz, leforrázás]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>Mentális egészség</td>\n",
       "      <td>Nekem sokat segített a pszichológus ebben a té...</td>\n",
       "      <td>Mi a neve ennek a mentális betegségnek? A pszi...</td>\n",
       "      <td>Mi a neve ennek a mentális betegségnek? A pszi...</td>\n",
       "      <td>[pszichológia, pszichológus, lélek, elme, fóbi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>Férfiak egészsége</td>\n",
       "      <td>Miért lenne baj, hogy \"még van fitymád\"? A fér...</td>\n",
       "      <td>Az a baj ha 15 évesen még van fitymám és hogy ...</td>\n",
       "      <td>Az a baj ha 15 évesen még van fitymám és hogy ...</td>\n",
       "      <td>[fityma, egészség, pénisz, betegség, normális,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>Betegségek</td>\n",
       "      <td>Legyél 1 srác és minden megjavul.</td>\n",
       "      <td>26 srác vagyok minden reggel hányinger és néha...</td>\n",
       "      <td>26 srác vagyok minden reggel hányinger és néha...</td>\n",
       "      <td>[pánikbetegség, hányinger, hasmenés]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>Fogak, szájápolás</td>\n",
       "      <td>Jaja, véletlen se az orvosra hallgass, aki 6+ ...</td>\n",
       "      <td>Húzassam ki? Vagy gyökérkezelés? A bal legháts...</td>\n",
       "      <td>Húzassam ki? Vagy gyökérkezelés?</td>\n",
       "      <td>[fog, gyökérkezelés]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             kategoriak                                             valasz  \\\n",
       "0  Sérülések, balesetek  Komolyan az eszem megáll! Azt, hogy leforrázta...   \n",
       "1     Mentális egészség  Nekem sokat segített a pszichológus ebben a té...   \n",
       "2     Férfiak egészsége  Miért lenne baj, hogy \"még van fitymád\"? A fér...   \n",
       "3            Betegségek                  Legyél 1 srác és minden megjavul.   \n",
       "4     Fogak, szájápolás  Jaja, véletlen se az orvosra hallgass, aki 6+ ...   \n",
       "\n",
       "                                       hosszu_kerdes  \\\n",
       "0  Ma sajnos leforráztam a kisbabám lábát! Úgy go...   \n",
       "1  Mi a neve ennek a mentális betegségnek? A pszi...   \n",
       "2  Az a baj ha 15 évesen még van fitymám és hogy ...   \n",
       "3  26 srác vagyok minden reggel hányinger és néha...   \n",
       "4  Húzassam ki? Vagy gyökérkezelés? A bal legháts...   \n",
       "\n",
       "                                        rovid_kerdes  \\\n",
       "0  Ma sajnos leforráztam a kisbabám lábát! Úgy go...   \n",
       "1  Mi a neve ennek a mentális betegségnek? A pszi...   \n",
       "2  Az a baj ha 15 évesen még van fitymám és hogy ...   \n",
       "3  26 srác vagyok minden reggel hányinger és néha...   \n",
       "4                   Húzassam ki? Vagy gyökérkezelés?   \n",
       "\n",
       "                                            keywords  \n",
       "0                      [baba, forró víz, leforrázás]  \n",
       "1  [pszichológia, pszichológus, lélek, elme, fóbi...  \n",
       "2  [fityma, egészség, pénisz, betegség, normális,...  \n",
       "3               [pánikbetegség, hányinger, hasmenés]  \n",
       "4                               [fog, gyökérkezelés]  "
      ]
     },
     "execution_count": 183,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "eg.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "metadata": {},
   "outputs": [],
   "source": [
    "p = eg.groupby(\"kategoriak\").size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 194,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = eg.hosszu_kerdes.tolist()\n",
    "labels = eg.valasz.tolist()\n",
    "\n",
    "with open(\"gyakori_seq2seq\", \"w+\", errors='surrogatepass') as f:\n",
    "    for line in zip(data, labels):\n",
    "        f.write(line[0] + \"\\t\" + line[1] + \"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 221,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:pytorch_pretrained_bert.tokenization:The pre-trained model you are loading is a cased model but you have not set `do_lower_case` to False. We are setting `do_lower_case=False` for you but you may want to check this behavior.\n",
      "INFO:pytorch_pretrained_bert.tokenization:loading vocabulary file https://s3.amazonaws.com/models.huggingface.co/bert/bert-base-multilingual-cased-vocab.txt from cache at /userhome/student/adaamko/.pytorch_pretrained_bert/96435fa287fbf7e469185f1062386e05a075cadbf6838b74da22bf64b080bc32.99bcd55fc66f4f3360bc49ba472b940b8dcf223ea6a345deb969d607ca900729\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from pytorch_pretrained_bert import BertTokenizer, BertModel, BertForMaskedLM\n",
    "\n",
    "# OPTIONAL: if you want to have more information on what's happening, activate the logger as follows\n",
    "import logging\n",
    "logging.basicConfig(level=logging.INFO)\n",
    "\n",
    "# Load pre-trained model tokenizer (vocabulary)\n",
    "tokenizer = BertTokenizer.from_pretrained('bert-base-multilingual-cased')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 220,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['[CLS]',\n",
       " 'komo',\n",
       " '##lya',\n",
       " '##n',\n",
       " '?',\n",
       " '?',\n",
       " 'en',\n",
       " 'ezt',\n",
       " 'nem',\n",
       " 'his',\n",
       " '##zem',\n",
       " ',',\n",
       " 'el',\n",
       " '.']"
      ]
     },
     "execution_count": 220,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Tokenized input\n",
    "text = \"[CLS] Komolyan?? én ezt nem hiszem, el.\"\n",
    "tokenized_text = tokenizer.tokenize(text)\n",
    "tokenized_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 222,
   "metadata": {},
   "outputs": [],
   "source": [
    "import hu_core_ud_lg\n",
    "\n",
    "nlp = hu_core_ud_lg.load()\n",
    "doc = nlp('Csiribiri csiribiri zabszalma - négy csillag közt alszom ma.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 235,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "\n",
    "from torchtext.datasets import TranslationDataset, Multi30k\n",
    "from torchtext.data import Field, BucketIterator, TabularDataset\n",
    "\n",
    "import spacy\n",
    "\n",
    "import random\n",
    "import math\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 227,
   "metadata": {},
   "outputs": [],
   "source": [
    "SEED = 1234\n",
    "\n",
    "random.seed(SEED)\n",
    "torch.manual_seed(SEED)\n",
    "torch.backends.cudnn.deterministic = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 232,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tokenize_hu(text):\n",
    "    \"\"\"\n",
    "    Tokenizes German text from a string into a list of strings (tokens) and reverses it\n",
    "    \"\"\"\n",
    "    return [tok.text for tok in nlp(text)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 233,
   "metadata": {},
   "outputs": [],
   "source": [
    "SRC = Field(tokenize = tokenize_hu, \n",
    "            init_token = '<sos>', \n",
    "            eos_token = '<eos>', \n",
    "            lower = True)\n",
    "\n",
    "TRG = Field(tokenize = tokenize_hu, \n",
    "            init_token = '<sos>', \n",
    "            eos_token = '<eos>', \n",
    "            lower = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 243,
   "metadata": {},
   "outputs": [
    {
     "ename": "UnicodeDecodeError",
     "evalue": "'utf-8' codec can't decode byte 0xed in position 5392: invalid continuation byte",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mUnicodeDecodeError\u001b[0m                        Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-243-8d984c799cc1>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      2\u001b[0m         \u001b[0mformat\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'csv'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mskip_header\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m         \u001b[0mtrain\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'train.tsv'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalidation\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'dev.tsv'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m         fields=[('src',SRC), (\"trg\",TRG)])\n\u001b[0m",
      "\u001b[0;32m~/miniconda3/lib/python3.7/site-packages/torchtext/data/dataset.py\u001b[0m in \u001b[0;36msplits\u001b[0;34m(cls, path, root, train, validation, test, **kwargs)\u001b[0m\n\u001b[1;32m     76\u001b[0m             \u001b[0mpath\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcls\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdownload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mroot\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     77\u001b[0m         train_data = None if train is None else cls(\n\u001b[0;32m---> 78\u001b[0;31m             os.path.join(path, train), **kwargs)\n\u001b[0m\u001b[1;32m     79\u001b[0m         val_data = None if validation is None else cls(\n\u001b[1;32m     80\u001b[0m             os.path.join(path, validation), **kwargs)\n",
      "\u001b[0;32m~/miniconda3/lib/python3.7/site-packages/torchtext/data/dataset.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, path, format, fields, skip_header, csv_reader_params, **kwargs)\u001b[0m\n\u001b[1;32m    269\u001b[0m                 \u001b[0mnext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mreader\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    270\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 271\u001b[0;31m             \u001b[0mexamples\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mmake_example\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mline\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfields\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mline\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mreader\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    272\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    273\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfields\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdict\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/lib/python3.7/site-packages/torchtext/data/dataset.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    269\u001b[0m                 \u001b[0mnext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mreader\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    270\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 271\u001b[0;31m             \u001b[0mexamples\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mmake_example\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mline\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfields\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mline\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mreader\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    272\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    273\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfields\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdict\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/lib/python3.7/site-packages/torchtext/utils.py\u001b[0m in \u001b[0;36municode_csv_reader\u001b[0;34m(unicode_csv_data, **kwargs)\u001b[0m\n\u001b[1;32m    137\u001b[0m             \u001b[0;32myield\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mcell\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdecode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'utf-8'\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mcell\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrow\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    138\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 139\u001b[0;31m         \u001b[0;32mfor\u001b[0m \u001b[0mline\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mcsv\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0municode_csv_data\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    140\u001b[0m             \u001b[0;32myield\u001b[0m \u001b[0mline\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    141\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/lib/python3.7/codecs.py\u001b[0m in \u001b[0;36mdecode\u001b[0;34m(self, input, final)\u001b[0m\n\u001b[1;32m    320\u001b[0m         \u001b[0;31m# decode input (taking the buffer into account)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    321\u001b[0m         \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbuffer\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 322\u001b[0;31m         \u001b[0;34m(\u001b[0m\u001b[0mresult\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mconsumed\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_buffer_decode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0merrors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfinal\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    323\u001b[0m         \u001b[0;31m# keep undecoded input until the next call\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    324\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbuffer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mconsumed\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mUnicodeDecodeError\u001b[0m: 'utf-8' codec can't decode byte 0xed in position 5392: invalid continuation byte"
     ]
    }
   ],
   "source": [
    "train, val = TabularDataset.splits(path=\".\",\n",
    "        format='csv', skip_header=True,\n",
    "        train='train.tsv', validation='dev.tsv',\n",
    "        fields=[('src',SRC), (\"trg\",TRG)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"gyakori_seq2seq\", \"r+\") as f:\n",
    "    for line in f:\n",
    "        f.write(line[0] + \"\\t\" + line[1] + \"\\n\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
